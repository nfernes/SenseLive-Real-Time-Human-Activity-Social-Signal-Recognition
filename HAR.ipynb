{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **PDIoT Coursework 3: Daily Physical Activity Classification**\n","\n","This notebook implements machine learning models to classify 11 daily physical activities using RESpeck accelerometer data:\n","\n","**Activities to Classify:**\n","1. Ascending\n","2. Decending\n","3. Lying down Back\n","4. Lying down Left\n","5. Lying down Right\n","6. Lying down Stomach\n","7. Miscellaneous movements\n","8. Normal walking\n","9. Running\n","10. Shuffle walking\n","11. Sitting/Standing\n"],"metadata":{"id":"activity_header"}},{"cell_type":"markdown","source":["## 1. Imports"],"metadata":{"id":"setup_header"}},{"cell_type":"code","source":["#all imports required\n","import pandas as pd\n","import numpy as np\n","import glob\n","import os\n","from collections import defaultdict\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import shutil\n","import zipfile\n","\n","from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from sklearn.utils.class_weight import compute_class_weight\n","from scipy.fft import fft\n","from scipy.signal import find_peaks\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.layers import (Input, Conv1D, MaxPooling1D, GlobalAveragePooling1D,\n","                                      Flatten, Dense, Dropout, BatchNormalization,\n","                                      LSTM, concatenate)\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.utils import plot_model\n","\n","np.random.seed(42)\n","tf.random.set_seed(42)"],"metadata":{"id":"imports"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#extract the respeck dataset zip file into the local data directory\n","data_zip = \"data/RESpeckData_Updated.zip\"\n","with zipfile.ZipFile(data_zip, 'r') as zip_ref:\n","    zip_ref.extractall(\"data/\")\n","\n","#define the path to the daily physical activity dataset\n","dataset_path = \"data/RESpeckData_Updated/daily_activity/\"\n","\n","#checking to confirm dataset path and available activity folders\n","print(f\"Dataset path: {dataset_path}\")\n","print(f\"Folders in dataset: {os.listdir(dataset_path)}\")"],"metadata":{"id":"LdwxhfMTBGWy","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1768387274878,"user_tz":0,"elapsed":106,"user":{"displayName":"Saniya Khan","userId":"02078379892508548353"}},"outputId":"13a078e4-f40c-4774-d2af-bc89cfd26eed"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'zipfile' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-890032720.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/RESpeckData_Updated.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data/RESpeckData_Updated/daily_activity/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'zipfile' is not defined"]}]},{"cell_type":"markdown","source":["## 2. Data Loading"],"metadata":{"id":"data_header"}},{"cell_type":"code","source":["#define a fixed mapping from activity names to integer class labels\n","activity_mapping = {\n","    'sittingStanding': 0,\n","    'lyingLeft': 1,\n","    'lyingRight': 2,\n","    'lyingBack': 3,\n","    'lyingStomach': 4,\n","    'normalWalking': 5,\n","    'running': 6,\n","    'ascending': 7,\n","    'descending': 8,\n","    'shuffleWalking': 9,\n","    'miscMovement': 10\n","}\n","\n","#define static activity classes used for performance evaluation\n","static_activities = [0, 1, 2, 3, 4]\n","\n","#define dynamic activity classes used for performance evaluation\n","dynamic_activities = [5, 6, 7, 8, 9, 10]\n","\n","#print a summary of all activity classes and their static or dynamic grouping\n","print(\"Activity Classes (11 total):\")\n","for activity, label in activity_mapping.items():\n","    activity_type = \"Static\" if label in static_activities else \"Dynamic\"\n","    print(f\"{label:2d}: {activity:20s} ({activity_type})\")\n"],"metadata":{"id":"data_setup"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_enhanced_features(window_data):\n","    features = []\n","\n","    #1.gravity-based orientation features estimated via window-mean acceleration\n","    mean_x = np.mean(window_data[:, 0])\n","    mean_y = np.mean(window_data[:, 1])\n","    mean_z = np.mean(window_data[:, 2])\n","\n","    #normalise mean acceleration to approximate gravity direction\n","    magnitude = np.sqrt(mean_x**2 + mean_y**2 + mean_z**2)\n","    gravity_x = mean_x / magnitude if magnitude > 0 else 0\n","    gravity_y = mean_y / magnitude if magnitude > 0 else 0\n","    gravity_z = mean_z / magnitude if magnitude > 0 else 0\n","\n","    #compute pitch and roll angles for posture discrimination\n","    pitch = np.arctan2(mean_y, np.sqrt(mean_x**2 + mean_z**2))\n","    roll = np.arctan2(mean_x, mean_z)\n","\n","    features.extend([gravity_x, gravity_y, gravity_z, pitch, roll])\n","\n","    #2.time-domain statistical features capturing amplitude and variability per axis\n","    for axis in range(3):\n","        axis_data = window_data[:, axis]\n","        features.extend([\n","            np.mean(axis_data),                  #average acceleration level\n","            np.std(axis_data),                   #signal dispersion\n","            np.var(axis_data),                   #power-related variability\n","            np.min(axis_data),                   #lower amplitude bound\n","            np.max(axis_data),                   #upper amplitude bound\n","            np.percentile(axis_data, 25),        #lower quartile\n","            np.percentile(axis_data, 75),        #upper quartile\n","            np.max(axis_data) - np.min(axis_data),  #dynamic range\n","            np.mean(np.abs(np.diff(axis_data)))  #temporal smoothness measure\n","        ])\n","\n","    #3.frequency-domain features capturing periodic locomotion patterns\n","    for axis in range(3):\n","        axis_data = window_data[:, axis]\n","        fft_vals = np.abs(fft(axis_data))\n","        fft_vals = fft_vals[:len(fft_vals)//2]  #only positive frequencies\n","\n","        #compute magnitude of fft and retain positive frequencies\n","        dominant_freq = np.argmax(fft_vals)\n","\n","        #energy in frequency bands\n","        #low band: 0-5 Hz, Mid band: 5-15 Hz, High band: 15-25 Hz\n","        #sampling rate is 12.5Hz, so Nyquist is 6.25Hz\n","        #adjust bands: Low: 0-2Hz, Mid: 2-4Hz, High: 4-6.25Hz\n","        total_energy = np.sum(fft_vals)\n","        low_band = np.sum(fft_vals[0:int(len(fft_vals)*0.32)])  # 0-2Hz\n","        mid_band = np.sum(fft_vals[int(len(fft_vals)*0.32):int(len(fft_vals)*0.64)])  # 2-4Hz\n","        high_band = np.sum(fft_vals[int(len(fft_vals)*0.64):])  # 4-6.25Hz\n","\n","        features.extend([\n","            dominant_freq,\n","            low_band / (total_energy + 1e-10),\n","            mid_band / (total_energy + 1e-10),\n","            high_band / (total_energy + 1e-10)\n","        ])\n","\n","    #4.step-related features derived from acceleration magnitude peaks\n","    accel_mag = np.sqrt(window_data[:, 0]**2 + window_data[:, 1]**2 + window_data[:, 2]**2)\n","\n","    #detect steps using prominence-based peak detection\n","    peaks, _ = find_peaks(accel_mag, distance=5, prominence=0.2)\n","    num_steps = len(peaks)\n","    step_rate = num_steps / len(window_data)\n","\n","    #quantify gait regularity via inter-step interval variability\n","    if len(peaks) > 1:\n","        inter_peak_intervals = np.diff(peaks)\n","        step_regularity = np.std(inter_peak_intervals)\n","    else:\n","        step_regularity = 0\n","\n","    features.extend([num_steps, step_rate, step_regularity])\n","\n","    return np.array(features)"],"metadata":{"id":"KLsWeaX17Uo5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_data_with_features(X):\n","    additional_features = []\n","    #extract features for each windowed sample\n","    for window in X:\n","        feats = extract_enhanced_features(window)\n","        additional_features.append(feats)\n","\n","    #convert list of per-window feature vectors into array for model input\n","    return np.array(additional_features)"],"metadata":{"id":"y6Z04jMTVXMY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compute_variance_threshold(X_train, y_train, static_activities, dynamic_activities, sample_size=5000):\n","    #subsample training windows to reduce computation on large datasets\n","    if len(X_train) > sample_size:\n","        indices = np.random.choice(len(X_train), sample_size, replace=False)\n","        X_sample = X_train[indices]\n","        y_sample = y_train[indices]\n","    else:\n","        X_sample = X_train\n","        y_sample = y_train\n","\n","    #estimate body acceleration variance for each window\n","    variances = []\n","    for window in X_sample:\n","        #compute acceleration magnitude across axes\n","        accel_mag = np.sqrt(\n","            window[:, 0]**2 +\n","            window[:, 1]**2 +\n","            window[:, 2]**2\n","        )\n","\n","        #remove constant gravity offset to emphasise dynamic motion\n","        body_accel = accel_mag - 9.81\n","\n","        #use variance as a motion intensity proxy\n","        var = np.var(body_accel)\n","        variances.append(var)\n","\n","    variances = np.array(variances)\n","\n","    #separate variance distributions for static and dynamic activities\n","    static_mask = np.isin(y_sample, static_activities)\n","    dynamic_mask = np.isin(y_sample, dynamic_activities)\n","\n","    static_variances = variances[static_mask]\n","    dynamic_variances = variances[dynamic_mask]\n","\n","    #derive conservative threshold from extreme percentiles\n","    max_static = np.percentile(static_variances, 95)\n","    min_dynamic = np.percentile(dynamic_variances, 5)\n","    threshold = (max_static + min_dynamic) / 2\n","\n","    #report statistics for transparency and analysis\n","    print(f\"Static variance 95th percentile: {max_static:.6f}\")\n","    print(f\"Dynamic variance 5th percentile: {min_dynamic:.6f}\")\n","    print(f\"Computed threshold: {threshold:.6f}\")\n","\n","    return threshold"],"metadata":{"id":"Hcw6xJFwfQJY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def apply_variance_filtering(y_pred_probs, X_test, variance_threshold,\n","                            static_activities, dynamic_activities,\n","                            confidence_threshold=0.95):\n","    y_pred = []\n","\n","    #post-process predictions window by window using motion variance\n","    for i, (probs, window) in enumerate(zip(y_pred_probs, X_test)):\n","\n","        #compute body acceleration variance as a motion intensity measure\n","        accel_mag = np.sqrt(\n","            window[:, 0]**2 +\n","            window[:, 1]**2 +\n","            window[:, 2]**2\n","        )\n","        body_accel = accel_mag - 9.81\n","        variance = np.var(body_accel)\n","\n","        #extract model confidence and most likely class\n","        max_prob = np.max(probs)\n","        model_pred = np.argmax(probs)\n","\n","        #trust model prediction when confidence exceeds threshold\n","        if max_prob > confidence_threshold:\n","            final_pred = model_pred\n","        else:\n","            #constrain prediction based on variance-derived activity type\n","            if variance < variance_threshold:\n","                #restrict classification to static activity subset\n","                static_probs = probs[static_activities]\n","                final_pred = static_activities[np.argmax(static_probs)]\n","            else:\n","                #restrict classification to dynamic activity subset\n","                dynamic_probs = probs[dynamic_activities]\n","                final_pred = dynamic_activities[np.argmax(dynamic_probs)]\n","\n","        y_pred.append(final_pred)\n","\n","    return np.array(y_pred)"],"metadata":{"id":"s1wpX7KRfgVO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  3. Data Processing and Preparation\n","\n"],"metadata":{"id":"AImf41yuqL5Q"}},{"cell_type":"code","source":["#define sliding window length and overlap for time-series segmentation\n","window_size = 50\n","step_size = 25\n","\n","#initialise lists to store windowed data, labels, and subject identifiers\n","X_all = []\n","y_all = []\n","subjects_all = []\n","\n","#iterate over each activity folder and corresponding class label\n","for activity, label in activity_mapping.items():\n","    folder = os.path.join(dataset_path, activity)\n","    for file in glob.glob(os.path.join(folder, \"*.csv\")):\n","        try:\n","            #extract subject identifier from filename for subject-wise splitting\n","            subject = file.split('_')[-1].split('.')[0]\n","\n","            #load tri-axial accelerometer data only\n","            data = pd.read_csv(file, usecols=['accelX', 'accelY', 'accelZ']).values\n","\n","            #segment continuous signals into overlapping sliding windows\n","            for i in range(0, len(data)-window_size, step_size):\n","                X_all.append(data[i:i+window_size])\n","                y_all.append(label)\n","                subjects_all.append(subject)\n","        except:\n","            #skip files that cannot be read or are incorrectly formatted\n","            continue\n","\n","#convert accumulated lists into numpy arrays for efficient processing\n","X = np.array(X_all)\n","y = np.array(y_all)\n","subjects = np.array(subjects_all)\n","\n","#print dataset statistics for verification and reporting\n","print(f\"Total windows: {len(X)}\")\n","print(f\"Total subjects: {len(np.unique(subjects))}\")\n"],"metadata":{"id":"processing_functions"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#identify all unique subjects in the dataset\n","unique_subjects = np.unique(subjects)\n","\n","#fix random seed to ensure reproducible subject splits\n","np.random.seed(42)\n","np.random.shuffle(unique_subjects)\n","\n","#define subject-level train, validation, and test split boundaries\n","train_end = int(len(unique_subjects) * 0.70)\n","val_end = int(len(unique_subjects) * 0.85)\n","\n","#split subjects to prevent data leakage across sets\n","train_subjects = unique_subjects[:train_end]\n","val_subjects = unique_subjects[train_end:val_end]\n","test_subjects = unique_subjects[val_end:]\n","\n","#create boolean masks for subject-wise data selection\n","train_mask = np.isin(subjects, train_subjects)\n","val_mask = np.isin(subjects, val_subjects)\n","test_mask = np.isin(subjects, test_subjects)\n","\n","#apply subject-wise masks to obtain final datasets\n","X_train = X[train_mask]\n","y_train = y[train_mask]\n","X_val = X[val_mask]\n","y_val = y[val_mask]\n","X_test = X[test_mask]\n","y_test = y[test_mask]\n","\n","#print split statistics for verification\n","print(f\"Train: {len(train_subjects)} subjects, {len(X_train)} windows\")\n","print(f\"Val:   {len(val_subjects)} subjects, {len(X_val)} windows\")\n","print(f\"Test:  {len(test_subjects)} subjects, {len(X_test)} windows\")\n","\n","#compute handcrafted feature vectors for each window in every split\n","X_train_gravity = prepare_data_with_features(X_train)\n","X_val_gravity = prepare_data_with_features(X_val)\n","X_test_gravity = prepare_data_with_features(X_test)\n","\n","#print feature tensor shapes to confirm consistency\n","print(f\"\\nFeatures shape - Train: {X_train_gravity.shape}, Val: {X_val_gravity.shape}, Test: {X_test_gravity.shape}\")"],"metadata":{"id":"TTGbZp5YjEq-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#normalise accelerometer data using statistics computed from the training set only\n","def normalise_data(X_train, X_val):\n","    #store original dimensions for reshaping\n","    n_train = X_train.shape[0]\n","    n_val = X_val.shape[0]\n","    window_size = X_train.shape[1]\n","    n_features = X_train.shape[2]\n","\n","    #flatten windowed data to apply standard scaling per feature\n","    X_train_flat = X_train.reshape(-1, n_features)\n","    X_val_flat = X_val.reshape(-1, n_features)\n","\n","    #fit scaler on training data and apply consistently to validation data\n","    scaler = StandardScaler()\n","    X_train_flat = scaler.fit_transform(X_train_flat)\n","    X_val_flat = scaler.transform(X_val_flat)\n","\n","    #reshape normalised data back to original window structure\n","    X_train_norm = X_train_flat.reshape(n_train, window_size, n_features)\n","    X_val_norm = X_val_flat.reshape(n_val, window_size, n_features)\n","\n","    return X_train_norm, X_val_norm, scaler\n","\n","#apply normalisation to training and validation sets\n","X_train_norm, X_val_norm, scaler = normalise_data(X_train, X_val)\n","\n","#apply the same trained scaler to the test set to avoid data leakage\n","X_test_norm = scaler.transform(X_test.reshape(-1, 3)).reshape(X_test.shape)\n","\n","#print shapes to verify correct normalisation and reshaping\n","print(f\"X_train_norm shape: {X_train_norm.shape}\")\n","print(f\"X_val_norm shape: {X_val_norm.shape}\")\n","print(f\"X_test_norm shape: {X_test_norm.shape}\")"],"metadata":{"id":"iZNEog54vOVm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#save the fitted scaler to disk for consistent preprocessing during deployment\n","with open('scaler.pkl', 'wb') as f:\n","    pickle.dump(scaler, f)\n","\n","#print scaler parameters for transparency and reproducibility\n","print(\"Scaler Parameters:\")\n","print(f\"Mean: {scaler.mean_}\")\n","print(f\"Std: {scaler.scale_}\")\n","\n","#confirm successful saving of the scaler object\n","print(\"\\nScaler saved as 'scaler.pkl'\")"],"metadata":{"id":"7TxMxfnowmZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#initialise one-hot encoder for multi-class classification\n","encoder = OneHotEncoder(sparse_output=False)\n","\n","#convert integer class labels into one-hot encoded vectors\n","y_train_new = encoder.fit_transform(y_train.reshape(-1, 1))\n","y_val_new = encoder.transform(y_val.reshape(-1, 1))\n","y_test_new = encoder.transform(y_test.reshape(-1, 1))\n","\n","#print encoded label shapes to verify correct conversion\n","print(f\"y_train_new: {y_train_new.shape}\")\n","print(f\"y_val_new: {y_val_new.shape}\")\n","print(f\"y_test_new: {y_test_new.shape}\")"],"metadata":{"id":"COo2QJwFmmGd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Build the ML Model"],"metadata":{"id":"I_etoGAarLnN"}},{"cell_type":"code","source":["def build_hybrid_model(input_shape_cnn, input_shape_features, num_classes):\n","\n","    #cnn branch processing raw tri-axial acceleration sequences\n","    cnn_input = Input(shape=input_shape_cnn, name='cnn_input')\n","\n","    #block 1: broad temporal kernels for low-level motion patterns\n","    x = Conv1D(64, 5, activation='relu', padding='same',\n","               kernel_regularizer=l2(0.001))(cnn_input)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling1D(2)(x)\n","    x = Dropout(0.3)(x)\n","\n","    #block 2: reduced kernel size to combine lower-level features\n","    x = Conv1D(128, 3, activation='relu', padding='same',\n","               kernel_regularizer=l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling1D(2)(x)\n","    x = Dropout(0.3)(x)\n","\n","    #block 3: high-level temporal abstraction prior to dense projection\n","    x = Conv1D(256, 3, activation='relu', padding='same',\n","               kernel_regularizer=l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n","    cnn_features = Dropout(0.3)(x)\n","\n","    #feature branch processing engineered window-level features\n","    feature_input = Input(shape=(input_shape_features,), name='feature_input')\n","    y = Dense(64, activation='relu')(feature_input)\n","    y = BatchNormalization()(y)\n","    y = Dropout(0.3)(y)\n","    y = Dense(32, activation='relu')(y)\n","    y = BatchNormalization()(y)\n","    feature_branch = Dropout(0.3)(y)\n","\n","    #fusion of learned temporal features and engineered descriptors\n","    combined = concatenate([cnn_features, feature_branch])\n","\n","    #fully connected fusion layers with strong regularisation\n","    z = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(combined)\n","    z = BatchNormalization()(z)\n","    z = Dropout(0.6)(z)\n","    z = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(z)\n","    z = Dropout(0.6)(z)\n","\n","    #softmax output for multi-class activity classification\n","    output = Dense(num_classes, activation='softmax')(z)\n","\n","    #compile model with categorical cross-entropy for multi-class learning\n","    model = Model(inputs=[cnn_input, feature_input], outputs=output)\n","    model.compile(\n","        optimizer='adam',\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model"],"metadata":{"id":"htpDATx8o3qP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_params = model.count_params()\n","print(f\"Total parameters: {total_params:,}\")"],"metadata":{"id":"BoTKoLq9gS9W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#define input shapes for cnn branch and handcrafted feature branch\n","input_shape_cnn = (X_train_norm.shape[1], X_train_norm.shape[2])\n","input_shape_features = X_train_gravity.shape[1]\n","\n","#define number of output classes for multi-class classification\n","num_classes = y_train_new.shape[1]\n","\n","#print model configuration details for verification\n","print(f\"CNN Input shape: {input_shape_cnn}\")\n","print(f\"Features shape: {input_shape_features}\")\n","print(f\"Number of classes: {num_classes}\")\n","\n","#build and initialise the hybrid activity recognition model\n","model = build_hybrid_model(input_shape_cnn, input_shape_features, num_classes)\n","\n","#print model architecture summary\n","model.summary()"],"metadata":{"id":"GkFZfamxr5La"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Train the Model"],"metadata":{"id":"GrRkfCqesa4i"}},{"cell_type":"code","source":["def build_hybrid_model(input_shape_cnn, input_shape_features, num_classes):\n","\n","    #cnn branch processing raw tri-axial acceleration sequences\n","    cnn_input = Input(shape=input_shape_cnn, name='cnn_input')\n","\n","    #block 1: broad temporal kernels for low-level motion patterns\n","    x = Conv1D(64, 5, activation='relu', padding='same',\n","               kernel_regularizer=l2(0.001))(cnn_input)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling1D(2)(x)\n","    x = Dropout(0.3)(x)\n","\n","    #block 2: reduced kernel size to combine lower-level features\n","    x = Conv1D(128, 3, activation='relu', padding='same',\n","               kernel_regularizer=l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = MaxPooling1D(2)(x)\n","    x = Dropout(0.3)(x)\n","\n","    #block 3: high-level temporal abstraction prior to dense projection\n","    x = Conv1D(256, 3, activation='relu', padding='same',\n","               kernel_regularizer=l2(0.001))(x)\n","    x = BatchNormalization()(x)\n","    x = Flatten()(x)\n","    x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n","    cnn_features = Dropout(0.3)(x)\n","\n","    #feature branch processing engineered window-level features\n","    feature_input = Input(shape=(input_shape_features,), name='feature_input')\n","    y = Dense(64, activation='relu')(feature_input)\n","    y = BatchNormalization()(y)\n","    y = Dropout(0.3)(y)\n","    y = Dense(32, activation='relu')(y)\n","    y = BatchNormalization()(y)\n","    feature_branch = Dropout(0.3)(y)\n","\n","    #fusion of learned temporal features and engineered descriptors\n","    combined = concatenate([cnn_features, feature_branch])\n","\n","    #fully connected fusion layers with strong regularisation\n","    z = Dense(128, activation='relu', kernel_regularizer=l2(0.01))(combined)\n","    z = BatchNormalization()(z)\n","    z = Dropout(0.6)(z)\n","    z = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(z)\n","    z = Dropout(0.6)(z)\n","\n","    #softmax output for multi-class activity classification\n","    output = Dense(num_classes, activation='softmax')(z)\n","\n","    #compile model with categorical cross-entropy for multi-class learning\n","    model = Model(inputs=[cnn_input, feature_input], outputs=output)\n","    model.compile(\n","        optimizer='adam',\n","        loss='categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","\n","    return model"],"metadata":{"id":"WPy9DwAKUr9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compute balanced class weights to mitigate class imbalance during training\n","class_weights = compute_class_weight(\n","    'balanced',\n","    classes=np.unique(y_train),\n","    y=y_train\n",")\n","\n","#map weights to class indices for keras training\n","class_weight_dict = dict(enumerate(class_weights))\n","\n","#print weights for transparency and reproducibility\n","print(\"Class weights:\", class_weight_dict)"],"metadata":{"id":"aimAe8rbWFQp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compute variance threshold from training data for static/dynamic separation\n","variance_threshold = compute_variance_threshold(\n","    X_train_norm,\n","    y_train,\n","    static_activities,\n","    dynamic_activities\n",")\n","\n","#persist threshold for consistent behaviour during deployment\n","with open('variance_threshold.pkl', 'wb') as f:\n","    pickle.dump(variance_threshold, f)\n","\n","#configure training callbacks to control overfitting and convergence\n","callbacks = [\n","    EarlyStopping(\n","        monitor='val_loss',\n","        patience=15,\n","        restore_best_weights=True,\n","        verbose=1\n","    ),\n","    ReduceLROnPlateau(\n","        monitor='val_loss',\n","        factor=0.5,\n","        patience=7,\n","        min_lr=1e-6,\n","        verbose=1\n","    )\n","]\n","\n","#train hybrid model with class weighting and validation split\n","#train hybrid model with class weighting and held-out validation subjects\n","history = model.fit(\n","    [X_train_norm, X_train_gravity],\n","    y_train_new,\n","    epochs=80,\n","    batch_size=64,\n","    validation_data=([X_val_norm, X_val_gravity], y_val_new),  # ← ADD THIS LINE\n","    callbacks=callbacks,\n","    class_weight=class_weight_dict,\n","    verbose=1\n",")\n"],"metadata":{"id":"GeVgyiPLsEi6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Evaluate the Model"],"metadata":{"id":"s7BNqdEi5Jiw"}},{"cell_type":"code","source":["#evaluate trained model on held-out test subjects using variance-based post-processing\n","print(\"Computing variance threshold from training data...\")\n","print(f\"Variance threshold: {variance_threshold:.6f}\\n\")\n","\n","#generate class probability predictions for test windows\n","print(\"Generating predictions on test set...\")\n","y_pred_probs = model.predict([X_test_norm, X_test_gravity])\n","\n","#apply physics-informed variance filtering to refine static/dynamic predictions\n","print(\"Applying variance-based filtering...\")\n","y_pred = apply_variance_filtering(\n","    y_pred_probs,\n","    X_test_norm,\n","    variance_threshold,\n","    static_activities,\n","    dynamic_activities,\n","    confidence_threshold=0.95\n",")\n","\n","#recover true class labels from one-hot encoding\n","y_true = np.argmax(y_test_new, axis=1)\n","\n","#compute overall subject-independent test accuracy\n","overall_accuracy = accuracy_score(y_true, y_pred)\n","print(f\"\\n{'='*60}\")\n","print(f\"TEST SET RESULTS (with variance filtering)\")\n","print(f\"{'='*60}\")\n","print(f\"Overall Accuracy: {overall_accuracy:.4f} ({overall_accuracy*100:.2f}%)\")\n","\n","#separate static and dynamic activity subsets for targeted evaluation\n","static_mask = np.isin(y_true, static_activities)\n","dynamic_mask = np.isin(y_true, dynamic_activities)\n","\n","static_accuracy = accuracy_score(y_true[static_mask], y_pred[static_mask])\n","dynamic_accuracy = accuracy_score(y_true[dynamic_mask], y_pred[dynamic_mask])\n","\n","#report performance against predefined static activity target\n","print(f\"\\nStatic Activities Accuracy: {static_accuracy:.4f} ({static_accuracy*100:.2f}%)\")\n","print(f\"  Target: 90% - {'good' if static_accuracy >= 0.90 else 'not good'}\")\n","\n","#report performance against predefined dynamic activity target\n","print(f\"\\nDynamic Activities Accuracy: {dynamic_accuracy:.4f} ({dynamic_accuracy*100:.2f}%)\")\n","print(f\"  Target: 85% - {'good' if dynamic_accuracy >= 0.85 else 'not good'}\")\n"],"metadata":{"id":"0kYZu354slke"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#plot training and validation performance to analyse learning behaviour\n","plt.figure(figsize=(14, 5))\n","\n","#plot accuracy curves to assess convergence and generalisation\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n","plt.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n","plt.title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n","plt.xlabel('Epoch', fontsize=12)\n","plt.ylabel('Accuracy', fontsize=12)\n","plt.legend(fontsize=11)\n","plt.grid(True, alpha=0.3)\n","\n","#plot loss curves to inspect optimisation stability and overfitting\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n","plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n","plt.title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n","plt.xlabel('Epoch', fontsize=12)\n","plt.ylabel('Loss', fontsize=12)\n","plt.legend(fontsize=11)\n","plt.grid(True, alpha=0.3)\n","\n","#save figure for inclusion in the final report\n","plt.tight_layout()\n","plt.savefig('figure1_training_curves.png', dpi=300, bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"nUcH9njO67Tl","executionInfo":{"status":"error","timestamp":1768387274908,"user_tz":0,"elapsed":11,"user":{"displayName":"Saniya Khan","userId":"02078379892508548353"}},"colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"0159fbed-6112-4ff5-9bfe-2ffde51a47cb"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'plt' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1473375270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"]}]},{"cell_type":"code","source":["#define readable activity class names for reporting and visualisation\n","activity_names = list(activity_mapping.keys())\n","\n","#print detailed precision, recall, and f1-score for each activity class\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true, y_pred, target_names=activity_names))\n","\n","#plot confusion matrix showing absolute prediction counts\n","plt.figure(figsize=(12, 10))\n","cm = confusion_matrix(y_true, y_pred)\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=activity_names,\n","            yticklabels=activity_names,\n","            cbar_kws={'label': 'Count'})\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix for Activity Classification')\n","plt.xticks(rotation=45, ha='right')\n","plt.yticks(rotation=0)\n","plt.tight_layout()\n","plt.savefig('figure3_confusion_matrix_counts.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","#compute row-normalised confusion matrix to analyse per-class accuracy\n","cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","#plot normalised confusion matrix for relative performance comparison\n","plt.figure(figsize=(12, 10))\n","sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='RdYlGn',\n","            xticklabels=activity_names,\n","            yticklabels=activity_names,\n","            cbar_kws={'label': 'Percentage'},\n","            vmin=0, vmax=1)\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title('Normalised Confusion Matrix', fontsize=14, fontweight='bold')\n","plt.xticks(rotation=45, ha='right')\n","plt.yticks(rotation=0)\n","plt.tight_layout()\n","plt.savefig('figure4_confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"o38HJSdn6_69"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#compute per-class precision, recall, f1-score, and support\n","precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred)\n","\n","#create a bar chart comparing precision, recall, and f1-score for each activity class\n","fig, ax = plt.subplots(figsize=(14, 6))\n","x = np.arange(len(activity_names))\n","width = 0.25\n","\n","#plot bars for precision, recall, and f1-score\n","bars1 = ax.bar(x - width, precision, width, label='Precision', color='salmon', alpha=0.8)\n","bars2 = ax.bar(x, recall, width, label='Recall', color='lightblue', alpha=0.8)\n","bars3 = ax.bar(x + width, f1, width, label='F1-Score', color='lightgreen', alpha=0.8)\n","\n","#draw target lines for static and dynamic activity accuracy thresholds\n","ax.axhline(y=0.90, color='black', linestyle='--', linewidth=2, label='Static Target (90%)')\n","ax.axhline(y=0.85, color='gray', linestyle='-.', linewidth=2, label='Dynamic Target (85%)')\n","\n","#set axis labels and title\n","ax.set_xlabel('Activity Class', fontsize=12)\n","ax.set_ylabel('Score', fontsize=12)\n","ax.set_title('Per-Class Performance Metrics', fontsize=14, fontweight='bold')\n","\n","#set tick labels to activity names\n","ax.set_xticks(x)\n","ax.set_xticklabels(activity_names, rotation=45, ha='right')\n","\n","#add legend, set y-axis limits, and add grid lines for readability\n","ax.legend(fontsize=11)\n","ax.set_ylim([0, 1.05])\n","ax.grid(True, alpha=0.3, axis='y')\n","\n","#adjust layout to prevent clipping and save figure for report\n","plt.tight_layout()\n","plt.savefig('figure2_per_class_performance.png', dpi=300, bbox_inches='tight')\n","plt.show()\n"],"metadata":{"id":"cENF3b5eTSaP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. Visualise Performance with Confusion Matrix"],"metadata":{"id":"748VdkaP8xqQ"}},{"cell_type":"code","source":["#perform leave-n-subjects-out cross-validation to evaluate subject generalisation\n","def leave_n_subjects_out_cv(X, y, subjects, num_folds=5):\n","    from collections import defaultdict\n","\n","    #identify all unique subjects and shuffle for random fold assignment\n","    unique_subjects = np.unique(subjects)\n","    np.random.seed(42)\n","    np.random.shuffle(unique_subjects)\n","\n","    #determine number of subjects per fold\n","    fold_size = len(unique_subjects) // num_folds\n","\n","    #store accuracy metrics for each fold\n","    fold_accuracies = []\n","    fold_static_accs = []\n","    fold_dynamic_accs = []\n","    per_class_accuracies = defaultdict(list)  # ← NEW: Track per-class\n","\n","    #iterate over each cross-validation fold\n","    for fold in range(num_folds):\n","        print(f\"\\nFold {fold + 1}/{num_folds}\")\n","\n","        #select test and training subjects for the current fold\n","        start_idx = fold * fold_size\n","        end_idx = start_idx + fold_size if fold < num_folds - 1 else len(unique_subjects)\n","        test_subs = unique_subjects[start_idx:end_idx]\n","        train_val_subs = np.setdiff1d(unique_subjects, test_subs)\n","\n","        #split train_val_subs into train and validation subjects\n","        np.random.shuffle(train_val_subs)\n","        val_size = int(len(train_val_subs) * 0.15 / 0.85)\n","        val_subs_fold = train_val_subs[:val_size]\n","        train_subs_fold = train_val_subs[val_size:]\n","\n","        print(f\"  Train subjects: {len(train_subs_fold)}, Val subjects: {len(val_subs_fold)}, Test subjects: {len(test_subs)}\")\n","\n","        #create subject-wise masks\n","        train_mask = np.isin(subjects, train_subs_fold)\n","        val_mask = np.isin(subjects, val_subs_fold)\n","        test_mask = np.isin(subjects, test_subs)\n","\n","        #split data\n","        X_train_fold = X[train_mask]\n","        y_train_fold = y[train_mask]\n","        X_val_fold = X[val_mask]\n","        y_val_fold = y[val_mask]\n","        X_test_fold = X[test_mask]\n","        y_test_fold = y[test_mask]\n","\n","        #normalise data\n","        X_train_norm_fold, X_val_norm_fold, scaler_fold = normalise_data(X_train_fold, X_val_fold)\n","        X_test_norm_fold = scaler_fold.transform(X_test_fold.reshape(-1, 3)).reshape(X_test_fold.shape)\n","\n","        #extract features\n","        X_train_gravity_fold = prepare_data_with_features(X_train_fold)\n","        X_val_gravity_fold = prepare_data_with_features(X_val_fold)\n","        X_test_gravity_fold = prepare_data_with_features(X_test_fold)\n","\n","        #one-hot encode\n","        encoder_fold = OneHotEncoder(sparse_output=False)\n","        y_train_oh = encoder_fold.fit_transform(y_train_fold.reshape(-1, 1))\n","        y_val_oh = encoder_fold.transform(y_val_fold.reshape(-1, 1))\n","        y_test_oh = encoder_fold.transform(y_test_fold.reshape(-1, 1))\n","\n","        #compute class weights\n","        class_weights_fold = compute_class_weight('balanced', classes=np.unique(y_train_fold), y=y_train_fold)\n","        class_weight_dict_fold = dict(enumerate(class_weights_fold))\n","\n","        #build model\n","        input_shape_cnn = (X_train_norm_fold.shape[1], X_train_norm_fold.shape[2])\n","        input_shape_features = X_train_gravity_fold.shape[1]\n","        num_classes = y_train_oh.shape[1]\n","        model_cv = build_hybrid_model(input_shape_cnn, input_shape_features, num_classes)\n","\n","        #define callbacks\n","        callbacks_cv = [\n","            EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=0),\n","            ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=7, min_lr=1e-6, verbose=0)\n","        ]\n","\n","        #train model\n","        model_cv.fit(\n","            [X_train_norm_fold, X_train_gravity_fold],\n","            y_train_oh,\n","            epochs=80,\n","            batch_size=64,\n","            validation_data=([X_val_norm_fold, X_val_gravity_fold], y_val_oh),\n","            callbacks=callbacks_cv,\n","            class_weight=class_weight_dict_fold,\n","            verbose=0\n","        )\n","\n","        #compute variance threshold\n","        variance_threshold_fold = compute_variance_threshold(\n","            X_train_norm_fold, y_train_fold, static_activities, dynamic_activities\n","        )\n","\n","        #predict\n","        y_pred_probs_fold = model_cv.predict([X_test_norm_fold, X_test_gravity_fold], verbose=0)\n","        y_pred_fold = apply_variance_filtering(\n","            y_pred_probs_fold, X_test_norm_fold, variance_threshold_fold,\n","            static_activities, dynamic_activities, confidence_threshold=0.95\n","        )\n","\n","        #get true labels\n","        y_true_fold = np.argmax(y_test_oh, axis=1)\n","\n","        #compute overall accuracy\n","        acc = accuracy_score(y_true_fold, y_pred_fold)\n","\n","        #compute static and dynamic accuracies\n","        static_mask_fold = np.isin(y_true_fold, static_activities)\n","        dynamic_mask_fold = np.isin(y_true_fold, dynamic_activities)\n","        static_acc = accuracy_score(y_true_fold[static_mask_fold], y_pred_fold[static_mask_fold]) if static_mask_fold.sum() > 0 else 0\n","        dynamic_acc = accuracy_score(y_true_fold[dynamic_mask_fold], y_pred_fold[dynamic_mask_fold]) if dynamic_mask_fold.sum() > 0 else 0\n","\n","\n","        for class_idx in range(num_classes):\n","            class_mask = (y_true_fold == class_idx)\n","            if class_mask.sum() > 0:\n","                class_acc = accuracy_score(y_true_fold[class_mask], y_pred_fold[class_mask])\n","                per_class_accuracies[class_idx].append(class_acc)\n","\n","\n","        #store fold results\n","        fold_accuracies.append(acc)\n","        fold_static_accs.append(static_acc)\n","        fold_dynamic_accs.append(dynamic_acc)\n","\n","        print(f\"  Overall: {acc:.4f}, Static: {static_acc:.4f}, Dynamic: {dynamic_acc:.4f}\")\n","\n","    #report summary statistics\n","\n","    print(\"CV summary:\")\n","    print(f\"Overall Accuracy:  {np.mean(fold_accuracies):.4f} ± {np.std(fold_accuracies):.4f}\")\n","    print(f\"Static Accuracy:   {np.mean(fold_static_accs):.4f} ± {np.std(fold_static_accs):.4f}\")\n","    print(f\"Dynamic Accuracy:  {np.mean(fold_dynamic_accs):.4f} ± {np.std(fold_dynamic_accs):.4f}\")\n","\n","\n","    print(\"Table 1 : Per-Class Cross-Validation Accuracy\")\n","\n","    print(f\"{'Activity':<20} {'CV Mean ± Std':<20} {'Category':<10}\")\n","\n","\n","    for class_idx, class_name in enumerate(activity_names):\n","        if class_idx in per_class_accuracies and len(per_class_accuracies[class_idx]) > 0:\n","            accs = per_class_accuracies[class_idx]\n","            mean_acc = np.mean(accs) * 100\n","            std_acc = np.std(accs) * 100\n","            category = \"Static\" if class_idx in static_activities else \"Dynamic\"\n","            print(f\"{class_name:<20} {mean_acc:5.2f}% ± {std_acc:5.2f}%   {category:<10}\")\n","        else:\n","            category = \"Static\" if class_idx in static_activities else \"Dynamic\"\n","            print(f\"{class_name:<20} {'No test samples':<20}   {category:<10}\")\n","\n","    return fold_accuracies, fold_static_accs, fold_dynamic_accs\n","\n","#run cross-validation\n","cv_results = leave_n_subjects_out_cv(X, y, subjects, num_folds=5)"],"metadata":{"id":"bT6lTijC8fKg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#convert trained Keras model to TensorFlow Lite format for edge deployment\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","#save the converted TFLite model to disk\n","with open('har_model.tflite', 'wb') as f:\n","    f.write(tflite_model)\n","\n","#report final model size to assess suitability for embedded devices\n","print(f\"Model size: {os.path.getsize('har_model.tflite') / 1024:.2f} KB\")\n","\n","#create output directory for deployment artefacts\n","output_dir = \"output/\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","#copy TFLite model and normalisation scaler for inference-time preprocessing\n","shutil.copy('har_model.tflite', os.path.join(output_dir, 'har_model.tflite'))\n","shutil.copy('scaler.pkl', os.path.join(output_dir, 'scaler.pkl'))\n","\n","print(f\"Files saved to {output_dir}\")"],"metadata":{"id":"vOXB_ER3m8KS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#collect and store all generated figures for reproducible reporting\n","for png_file in glob.glob(\"*.png\"):\n","    shutil.copy(png_file, os.path.join(output_dir, png_file))\n","\n","#confirm successful export of visual results\n","print(\"Figures saved to output/\")"],"metadata":{"id":"PXi_Hdht88Rw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing on New Dataset\n"],"metadata":{"id":"kkVRJ4lcc_j6"}},{"cell_type":"code","source":["#load previously saved normalisation scaler to ensure consistent preprocessing\n","with open('scaler.pkl', 'rb') as f:\n","    scaler = pickle.load(f)\n","\n","#load tflite model for lightweight inference on unseen data\n","interpreter = tf.lite.Interpreter(model_path='har_model.tflite')\n","interpreter.allocate_tensors()\n","input_details = interpreter.get_input_details()\n","output_details = interpreter.get_output_details()\n","\n","#extract external dataset used for generalisation testing\n","external_data_zip = \"data/RESpeckData_2526_fixed.zip\"\n","with zipfile.ZipFile(external_data_zip, 'r') as zip_ref:\n","    zip_ref.extractall(\"data/\")\n","\n","#path to external dataset containing unseen subjects\n","new_dataset_path = \"data/RESpeckData_2526_fixed/daily_activity/\"\n","\n","#redefine activity mapping to ensure label consistency with training\n","new_dataset_path = \"/content/RESpeckData_2526_fixed/daily_activity/\"\n","activity_mapping = {'sittingStanding': 0, 'lyingLeft': 1, 'lyingRight': 2,\n","                    'lyingBack': 3, 'lyingStomach': 4, 'normalWalking': 5,\n","                    'running': 6, 'ascending': 7, 'descending': 8,\n","                    'shuffleWalking': 9, 'miscMovement': 10}\n","\n","#group activities into static and dynamic for targeted performance analysis\n","static_activities = [0, 1, 2, 3, 4]\n","dynamic_activities = [5, 6, 7, 8, 9, 10]\n","\n","#load and segment external dataset using identical windowing strategy\n","X_test_ext, y_test_ext = [], []\n","for activity, label in activity_mapping.items():\n","    for file in glob.glob(os.path.join(new_dataset_path, activity, \"*.csv\")):\n","        try:\n","            df = pd.read_csv(file)\n","\n","            #select accelerometer axes irrespective of column naming\n","            accel_cols = [col for col in df.columns if 'accel' in col.lower()]\n","            if len(accel_cols) >= 3:\n","                data = df[accel_cols[:3]].values\n","\n","            #apply sliding window segmentation consistent with training\n","            for i in range(0, len(data)-50, 25):\n","                X_test_ext.append(data[i:i+50])\n","                y_test_ext.append(label)\n","\n","        except Exception as e:\n","            print(f\"Error reading {file}: {e}\")\n","            continue\n","\n","#convert external test data to numpy arrays\n","X_test_ext = np.array(X_test_ext)\n","y_test_ext = np.array(y_test_ext)\n","\n","print(f\"Loaded {len(X_test_ext)} windows\")\n","\n","#extract identical enhanced feature set to avoid train test mismatch\n","X_gravity_ext = prepare_data_with_features(X_test_ext)\n","\n","#apply training scaler to external data for fair evaluation\n","X_norm_ext = scaler.transform(X_test_ext.reshape(-1, 3)).reshape(X_test_ext.shape)\n","\n","#perform inference using tflite interpreter window by window\n","predictions = []\n","for i in range(len(X_norm_ext)):\n","    interpreter.set_tensor(input_details[0]['index'], X_norm_ext[i:i+1].astype(np.float32))\n","    interpreter.set_tensor(input_details[1]['index'], X_gravity_ext[i:i+1].astype(np.float32))\n","    interpreter.invoke()\n","    predictions.append(interpreter.get_tensor(output_details[0]['index'])[0])\n","\n","#convert predicted probabilities to class labels\n","y_pred_ext = np.argmax(predictions, axis=1)\n","\n","#report external dataset performance to assess model generalisation\n","print(f\"\\nExternal Dataset Results:\")\n","print(f\"Overall: {accuracy_score(y_test_ext, y_pred_ext):.4f}\")\n","print(f\"Static:  {accuracy_score(y_test_ext[np.isin(y_test_ext, static_activities)], y_pred_ext[np.isin(y_test_ext, static_activities)]):.4f}\")\n","print(f\"Dynamic: {accuracy_score(y_test_ext[np.isin(y_test_ext, dynamic_activities)], y_pred_ext[np.isin(y_test_ext, dynamic_activities)]):.4f}\")\n","\n","#print per class precision recall and f1 score on unseen data\n","print(\"\\n\", classification_report(y_test_ext, y_pred_ext, target_names=list(activity_mapping.keys())))\n","\n","#define class names for external confusion matrix visualisation\n","activity_names_ext = list(activity_mapping.keys())\n","\n","#plot confusion matrix showing absolute error distribution on external data\n","plt.figure(figsize=(12, 10))\n","cm_ext = confusion_matrix(y_test_ext, y_pred_ext)\n","sns.heatmap(cm_ext, annot=True, fmt='d', cmap='Oranges',\n","            xticklabels=activity_names_ext,\n","            yticklabels=activity_names_ext,\n","            cbar_kws={'label': 'Count'})\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.title('Confusion Matrix - External Dataset (RESpeckData 2526)')\n","plt.xticks(rotation=45, ha='right')\n","plt.yticks(rotation=0)\n","plt.tight_layout()\n","plt.savefig('figure6_external_test_cm_counts.png', dpi=300, bbox_inches='tight')\n","plt.show()\n","\n","#compute normalised confusion matrix to evaluate relative class performance\n","cm_ext_normalized = cm_ext.astype('float') / cm_ext.sum(axis=1)[:, np.newaxis]\n","\n","#plot normalised confusion matrix for generalisation analysis\n","plt.figure(figsize=(12, 10))\n","sns.heatmap(cm_ext_normalized, annot=True, fmt='.2%', cmap='RdYlGn',\n","            xticklabels=activity_names_ext,\n","            yticklabels=activity_names_ext,\n","            cbar_kws={'label': 'Percentage'},\n","            vmin=0, vmax=1)\n","plt.xlabel('Predicted', fontsize=12)\n","plt.ylabel('True', fontsize=12)\n","plt.title('Normalised Confusion Matrix - External Dataset (RESpeckData 2526)', fontsize=14, fontweight='bold')\n","plt.xticks(rotation=45, ha='right')\n","plt.yticks(rotation=0)\n","plt.tight_layout()\n","plt.savefig('figure7_testing_normalised_matrix.png', dpi=300, bbox_inches='tight')\n","plt.show()"],"metadata":{"id":"qTshW8-BdCXG"},"execution_count":null,"outputs":[]}]}
